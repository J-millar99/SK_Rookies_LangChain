{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "60909fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello LangChain\n"
     ]
    }
   ],
   "source": [
    "print('Hello LangChain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a05fb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "183ff9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['input'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='ë‹¹ì‹ ì€ ê°œë°œìì…ë‹ˆë‹¤.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "# prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [ (\"system\", \"ë‹¹ì‹ ì€ ê°œë°œìì…ë‹ˆë‹¤.\") , \n",
    "     (\"user\", \"{input}\") ]\n",
    ")\n",
    "print(prompt)\n",
    "\n",
    "prompt_text = prompt.format(input=\"ìë°”ëŠ” ë¬´ì—‡ì¸ê°€ìš”? ìì„¸í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1b12d55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x000001EDEF8C4AD0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001EDEFB26030> root_client=<openai.OpenAI object at 0x000001EDEFBBA5A0> root_async_client=<openai.AsyncOpenAI object at 0x000001EDEF8C5640> model_name='meta-llama/llama-4-scout-17b-16e-instruct' temperature=0.7 model_kwargs={} openai_api_key=SecretStr('**********') openai_api_base='https://api.groq.com/openai/v1'\n"
     ]
    }
   ],
   "source": [
    "# Groq APIë¥¼ ì‚¬ìš©í•˜ëŠ” ChatOpenAI ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4bbbba",
   "metadata": {},
   "source": [
    "### LCEL\n",
    "* Prompt + LLMì„ Chainìœ¼ë¡œ ì—°ê²°í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6c039ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='You are an expert in AI Expert.Answer the question. <Question>: {input}ì— ëŒ€í•´ ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"\" \\\n",
    "\"You are an expert in AI Expert.\" \\\n",
    "\"Answer the question. <Question>: {input}ì— ëŒ€í•´ ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "85e9f3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
     ]
    }
   ],
   "source": [
    "# chain ì—°ê²° (LCEL)\n",
    "chain = prompt | llm\n",
    "print(type(chain))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36b2542",
   "metadata": {},
   "source": [
    "### LCEL\n",
    "* Prompt + LLM + outputparserë¥¼ Chainìœ¼ë¡œ ì—°ê²°í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "be0d06d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# chain ì—°ê²° (LCEL) prompt + llm + outputparser\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain2 = prompt | llm | output_parser\n",
    "print(type(chain2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b8968c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ëŠ” ì‚¬ëŒì˜ ë‡Œê°€ í•™ìŠµí•˜ëŠ” ë°©ì‹ê³¼ ìœ ì‚¬í•©ë‹ˆë‹¤. ì»´í“¨í„°ê°€ ë°ì´í„°ë¥¼ í†µí•´ ìŠ¤ìŠ¤ë¡œ í•™ìŠµí•˜ê³ , ì£¼ì–´ì§„ ë¬¸ì œì— ëŒ€í•œ í•´ê²° ëŠ¥ë ¥ì„ í‚¤ìš°ëŠ” ê²ƒì…ë‹ˆë‹¤. ì—¬ê¸°ì—ëŠ” ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ëŸ¬ë‹ì´ í¬í•¨ë©ë‹ˆë‹¤.\n",
      "\n",
      "1. **ë°ì´í„° ìˆ˜ì§‘**: ìš°ì„  ì¸ê³µì§€ëŠ¥ì´ í•™ìŠµí•  ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤. ì´ ë°ì´í„°ëŠ” ë¬¸ì œì— ëŒ€í•œ ë‹µì„ í¬í•¨í•˜ê³  ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\n",
      "\n",
      "2. **ë°ì´í„° ì „ì²˜ë¦¬**: ìˆ˜ì§‘í•œ ë°ì´í„°ë¥¼ ê¹¨ë—í•˜ê²Œ ì •ë¦¬í•˜ê³ , í•„ìš”í•œ ê²½ìš° ë°ì´í„°ë¥¼ ë³€í™˜í•˜ê±°ë‚˜ ê°€ê³µí•©ë‹ˆë‹¤.\n",
      "\n",
      "3. **ëª¨ë¸ ì„ íƒ**: í•™ìŠµì— ì‚¬ìš©í•  ì•Œê³ ë¦¬ì¦˜ ë˜ëŠ” ëª¨ë¸ì„ ì„ íƒí•©ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ ë°ì´í„°ë¡œë¶€í„° íŒ¨í„´ì„ í•™ìŠµí•  ìˆ˜ ìˆëŠ” êµ¬ì¡°ë¡œ ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "4. **í•™ìŠµ**: ì¤€ë¹„í•œ ë°ì´í„°ë¥¼ ëª¨ë¸ì— ì…ë ¥í•˜ì—¬ í•™ìŠµì‹œí‚µë‹ˆë‹¤. ì´ ê³¼ì •ì—ì„œëŠ” ëª¨ë¸ì´ ì…ë ¥ëœ ë°ì´í„°ë¡œë¶€í„° íŒ¨í„´ì„ ì¸ì‹í•˜ê³ , ê·¸ íŒ¨í„´ì„ í†µí•´ ê²°ì •ì„ ë‚´ë¦´ ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤. ëª¨ë¸ì€ ì˜ˆì¸¡ì„ í•˜ê³ , ì‹¤ì œ ë‹µê³¼ì˜ ì˜¤ì°¨ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. ì´ ì˜¤ì°¨ë¥¼ ì¤„ì´ê¸° ìœ„í•´ ëª¨ë¸ì˜ ë‚´ë¶€ ë§¤ê°œë³€ìˆ˜(ê°€ì¤‘ì¹˜)ë¥¼ ì¡°ì •í•˜ëŠ” ê³¼ì •ì„ ë°˜ë³µí•©ë‹ˆë‹¤.\n",
      "\n",
      "5. **í‰ê°€**: í•™ìŠµì´ ì™„ë£Œëœ í›„, ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤. ì´ëŠ” ë³„ë„ì˜ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì˜ ì˜ˆì¸¡ ì •í™•ë„ë¥¼ í™•ì¸í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤.\n",
      "\n",
      "6. **íŠœë‹**: ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ë§Œì¡±ìŠ¤ëŸ½ì§€ ì•Šì„ ê²½ìš°, ëª¨ë¸ì˜ êµ¬ì¡°, í•™ìŠµ ë°ì´í„°, í•˜ì´í¼íŒŒë¼ë¯¸í„°(ëª¨ë¸ì˜ ì„¤ì •ê°’) ë“±ì„ ì¡°ì •í•˜ì—¬ ì„±ëŠ¥ì„ ê°œì„ í•©ë‹ˆë‹¤.\n",
      "\n",
      "ì˜ˆë¥¼ ë“¤ì–´, ì´ë¯¸ì§€ ì¸ì‹ ëª¨ë¸ì„ ë§Œë“ ë‹¤ê³  ê°€ì •í•´ ë´…ì‹œë‹¤. \n",
      "\n",
      "- **ë°ì´í„° ìˆ˜ì§‘**: ì¸í„°ë„·ì—ì„œ ê³ ì–‘ì´, ê°œ ë“± ë‹¤ì–‘í•œ ë™ë¬¼ì˜ ì‚¬ì§„ì„ ìˆ˜ì§‘í•©ë‹ˆë‹¤.\n",
      "- **ë°ì´í„° ì „ì²˜ë¦¬**: ì´ë¯¸ì§€ì˜ í¬ê¸°ë¥¼ ì¡°ì •í•˜ê³ , ë…¸ì´ì¦ˆë¥¼ ì œê±°í•˜ëŠ” ë“±ì˜ ì‘ì—…ì„ í•©ë‹ˆë‹¤.\n",
      "- **ëª¨ë¸ ì„ íƒ**: ì´ë¯¸ì§€ë¥¼ ë¶„ë¥˜í•  ìˆ˜ ìˆëŠ” ì‹ ê²½ë§ ëª¨ë¸ì„ ì„ íƒí•©ë‹ˆë‹¤.\n",
      "- **í•™ìŠµ**: ê³ ì–‘ì´ëŠ” 1, ê°œëŠ” 0ì´ë¼ëŠ” ë¼ë²¨ê³¼ í•¨ê»˜ ì´ë¯¸ì§€ë¥¼ ëª¨ë¸ì— ì…ë ¥í•˜ì—¬ í•™ìŠµí•©ë‹ˆë‹¤. ëª¨ë¸ì€ ì´ë¯¸ì§€ë¥¼ ë³´ê³  ì–´ë–¤ ë™ë¬¼ì¸ì§€ ì˜ˆì¸¡í•˜ê³ , ì‹¤ì œ ë‹µê³¼ ë¹„êµí•˜ì—¬ ì˜¤ì°¨ë¥¼ ì¤„ì…ë‹ˆë‹¤.\n",
      "- **í‰ê°€**: ìƒˆë¡œìš´ ì´ë¯¸ì§€ë“¤ì„ ëª¨ë¸ì— ì…ë ¥í•˜ì—¬ ì–¼ë§ˆë‚˜ ì •í™•í•˜ê²Œ ë¶„ë¥˜í•  ìˆ˜ ìˆëŠ”ì§€ í‰ê°€í•©ë‹ˆë‹¤.\n",
      "- **íŠœë‹**: ëª¨ë¸ì˜ ì •í™•ë„ê°€ ë‚®ì„ ê²½ìš°, ë” ë§ì€ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê±°ë‚˜ ëª¨ë¸ì˜ êµ¬ì¡°ë¥¼ ë³€ê²½í•˜ëŠ” ë“±ì˜ ì‘ì—…ì„ í•©ë‹ˆë‹¤.\n",
      "\n",
      "ì´ì²˜ëŸ¼ ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì€ ë°ì´í„°ë¥¼ í†µí•´ í•™ìŠµí•˜ê³ , ê·¸ í•™ìŠµì„ í†µí•´ ì£¼ì–´ì§„ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ëŠ¥ë ¥ì„ í‚¤ì›ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# chain í˜¸ì¶œ\n",
    "try:\n",
    "    result = chain.invoke({\"input\": \"ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬\"})\n",
    "    print(type(result))\n",
    "    print(result.content)\n",
    "except Exception as e:\n",
    "    print(f\"ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5e22b5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "LangChainì€ ë‹¤ì–‘í•œ AI ê´€ë ¨ ì œí’ˆì„ ì œê³µí•˜ëŠ” íšŒì‚¬ì…ë‹ˆë‹¤. LangChainì˜ ì£¼ìš” ì œí’ˆì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **LangSmith**: LangSmithëŠ” LangChainì—ì„œ ì œê³µí•˜ëŠ” ëŒ€í™”í˜• AI í”Œë«í¼ì…ë‹ˆë‹¤. ê°œë°œìê°€ ì‰½ê²Œ ëŒ€í™”í˜• AI ëª¨ë¸ì„ êµ¬ì¶•, í…ŒìŠ¤íŠ¸ ë° ë°°í¬í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•©ë‹ˆë‹¤. LangSmithë¥¼ í†µí•´ ê°œë°œìëŠ” ìì—°ì–´ ì²˜ë¦¬(NLP) ë° ëŒ€í™”í˜• AI ëª¨ë¸ì„ ë¹ ë¥´ê²Œ êµ¬ì¶•í•˜ê³ , ì´ë¥¼ ë‹¤ì–‘í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ì— í†µí•©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "2. **LangServe**: LangServeëŠ” LangChainì—ì„œ ì œê³µí•˜ëŠ” API ê¸°ë°˜ì˜ ì–¸ì–´ ëª¨ë¸ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤. LangServeë¥¼ í†µí•´ ê°œë°œìëŠ” ì‚¬ì „ í›ˆë ¨ëœ ì–¸ì–´ ëª¨ë¸ì„ ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆìœ¼ë©°, ì´ë¥¼ ìì‹ ì˜ ì• í”Œë¦¬ì¼€ì´ì…˜ì— í†µí•©í•˜ì—¬ ìì—°ì–´ ì²˜ë¦¬ ê¸°ëŠ¥ì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "3. **LangChain**: LangChainì˜ í•µì‹¬ ì œí’ˆì¸ LangChain ìì²´ëŠ” ê°œë°œìê°€ ìì—°ì–´ ì²˜ë¦¬ ë° ëŒ€í™”í˜• AI ëª¨ë¸ì„ êµ¬ì¶•í•˜ê³  ë°°í¬í•  ìˆ˜ ìˆëŠ” í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. LangChainì€ ë‹¤ì–‘í•œ ì–¸ì–´ ëª¨ë¸ê³¼ ë°ì´í„°ë¥¼ ì§€ì›í•˜ë©°, ê°œë°œìê°€ ì‰½ê²Œ ëª¨ë¸ì„ í›ˆë ¨ì‹œí‚¤ê³  ì• í”Œë¦¬ì¼€ì´ì…˜ì— í†µí•©í•  ìˆ˜ ìˆë„ë¡ ë•ìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì´ëŸ¬í•œ ì œí’ˆë“¤ì€ LangChainì´ ì œê³µí•˜ëŠ” AI ì†”ë£¨ì…˜ì˜ ì¼ë¶€ì´ë©°, ê°œë°œìì™€ ê¸°ì—…ì´ ìì—°ì–´ ì²˜ë¦¬ ë° ëŒ€í™”í˜• AIë¥¼ í™œìš©í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•©ë‹ˆë‹¤. LangChainì˜ ì œí’ˆë“¤ì€ ì‚¬ìš©ìì˜ ìš”êµ¬ì— ë”°ë¼ ë‹¤ì–‘í•œ ë°©ì‹ìœ¼ë¡œ í™œìš©ë  ìˆ˜ ìˆìœ¼ë©°, ìì—°ì–´ ì²˜ë¦¬ ë¶„ì•¼ì—ì„œ ê°•ë ¥í•œ ë„êµ¬ë¡œ í‰ê°€ë°›ê³  ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# chain í˜¸ì¶œ\n",
    "try:\n",
    "    result = chain2.invoke({\"input\": \"LangChainì˜ Products(ì œí’ˆ)ëŠ” ì–´ë–¤ ê²ƒë“¤ì´ ìˆë‚˜ìš”? ì˜ˆë¥¼ ë“¤ì–´ LangSmith, LangServeê°™ì€ productsê°€ ìˆì–´.\"})\n",
    "    print(type(result))\n",
    "    print(result)\n",
    "except Exception as e:\n",
    "    print(f\"ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5547e7",
   "metadata": {},
   "source": [
    "### Runnableì˜ stream() í•¨ìˆ˜ í˜¸ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "18c114a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object RunnableSequence.stream at 0x000001EDF24417B0>\n",
      "ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ëŠ” í¬ê²Œ ë‹¤ìŒê³¼ ê°™ì€ ê³¼ì •ìœ¼ë¡œ ì„¤ëª…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "1. **ë°ì´í„° ìˆ˜ì§‘**: ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ê¸° ìœ„í•´ì„œëŠ” ë¨¼ì €å¤§é‡çš„ì˜ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì´ ë°ì´í„°ëŠ” ë¬¸ì œì˜ ìœ í˜•ì— ë”°ë¼ ë‹¬ë¼ì§€ë©°, ì˜ˆë¥¼ ë“¤ì–´ ì´ë¯¸ì§€ ì¸ì‹ ëª¨ë¸ì„ ë§Œë“¤ë ¤ë©´ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³ , ìì—°ì–´ ì²˜ë¦¬ ëª¨ë¸ì„ ë§Œë“¤ë ¤ë©´ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.\n",
      "\n",
      "2. **ë°ì´í„° ì „ì²˜ë¦¬**: ìˆ˜ì§‘ëœ ë°ì´í„°ëŠ” ëª¨ë¸ì— ì‚¬ìš©í•˜ê¸° ì „ì— ì „ì²˜ë¦¬ ê³¼ì •ì„ ê±°ì¹©ë‹ˆë‹¤. ì´ ê³¼ì •ì—ì„œëŠ” ë°ì´í„°ì˜ ì˜¤ë¥˜ë¥¼ ìˆ˜ì •í•˜ê±°ë‚˜, ë°ì´í„°ë¥¼ ì •ê·œí™”í•˜ê±°ë‚˜, í•„ìš”í•œ ê²½ìš° ë°ì´í„°ë¥¼ ë³€í™˜í•˜ëŠ” ì‘ì—… ë“±ì´ í¬í•¨ë©ë‹ˆë‹¤.\n",
      "\n",
      "3. **ëª¨ë¸ ì„ íƒ**: ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì—ëŠ” ì—¬ëŸ¬ ê°€ì§€ ìœ í˜•ì´ ìˆìœ¼ë©°, í•´ê²°í•˜ë ¤ëŠ” ë¬¸ì œì˜ ì„±ê²©ì— ë”°ë¼ ì í•©í•œ ëª¨ë¸ì„ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì´ë¯¸ì§€ ì¸ì‹ ë¬¸ì œëŠ” í•©ì„±ê³± ì‹ ê²½ë§(CNN), ìì—°ì–´ ì²˜ë¦¬ ë¬¸ì œëŠ” ìˆœí™˜ ì‹ ê²½ë§(RNN) ë˜ëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "4. **ëª¨ë¸ í•™ìŠµ**: ì„ íƒëœ ëª¨ë¸ì— ì „ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ ì…ë ¥í•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµì‹œí‚µë‹ˆë‹¤. ì´ ê³¼ì •ì—ì„œëŠ” ëª¨ë¸ì´ ë°ì´í„°ë¡œë¶€í„° íŒ¨í„´ì´ë‚˜ ê·œì¹™ì„ ìŠ¤ìŠ¤ë¡œ ë°œê²¬í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤. ëª¨ë¸ì˜ í•™ìŠµì—ëŠ” í¬ê²Œ **ê°ë… í•™ìŠµ**ê³¼ **ë¹„ê°ë… í•™ìŠµ** ë‘ ê°€ì§€ ë°©ë²•ì´ ìˆìŠµë‹ˆë‹¤.\n",
      "   - **ê°ë… í•™ìŠµ**: ëª¨ë¸ì´ ì…ë ¥ ë°ì´í„°ì™€ ê·¸ì— ëŒ€ì‘í•˜ëŠ” ì¶œë ¥(ë ˆì´ë¸”)ì„ í•¨ê»˜ í•™ìŠµí•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. ëª¨ë¸ì€ ì…ë ¥ ë°ì´í„°ì™€ ì¶œë ¥ ê°„ì˜ ê´€ê³„ë¥¼ í•™ìŠµí•˜ì—¬, ìƒˆë¡œìš´ ì…ë ¥ ë°ì´í„°ì— ëŒ€í•´ ì˜¬ë°”ë¥¸ ì¶œë ¥ì„ ì˜ˆì¸¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "   - **ë¹„ê°ë… í•™ìŠµ**: ëª¨ë¸ì´ ì…ë ¥ ë°ì´í„°ë§Œìœ¼ë¡œ í•™ìŠµí•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. ì´ ê²½ìš°, ëª¨ë¸ì€ ë°ì´í„°ì—ì„œ íŒ¨í„´ì´ë‚˜ êµ¬ì¡°ë¥¼ ë°œê²¬í•˜ë ¤ê³  ì‹œë„í•˜ë©°, ì£¼ë¡œ ë°ì´í„°ì˜ í´ëŸ¬ìŠ¤í„°ë§ì´ë‚˜ ì°¨ì› ì¶•ì†Œì— ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
      "\n",
      "5. **ëª¨ë¸ í‰ê°€**: í•™ìŠµëœ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ í•™ìŠµ ë°ì´í„°ì™€ëŠ” ë³„ë„ì˜ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì¸¡ì •í•©ë‹ˆë‹¤. í‰ê°€ ì§€í‘œëŠ” ë¬¸ì œì˜ ìœ í˜•ì— ë”°ë¼ ë‹¬ë¼ì§€ë©°, ë¶„ë¥˜ ë¬¸ì œì—ì„œëŠ” ì •í™•ë„, ì •ë°€ë„, ì¬í˜„ìœ¨, F1 ì ìˆ˜ ë“±ì„ ì‚¬ìš©í•˜ê³ , íšŒê·€ ë¬¸ì œì—ì„œëŠ” í‰ê·  ì œê³± ì˜¤ì°¨(MSE) ë“±ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
      "\n",
      "6. **ëª¨ë¸ ìµœì í™”**: ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ëª¨ë¸ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•˜ê±°ë‚˜, ëª¨ë¸ì˜ êµ¬ì¡°ë¥¼ ë³€ê²½í•˜ëŠ” ë“±ì˜ ìµœì í™” ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì´ ê³¼ì •ì€ ë°˜ë³µì ìœ¼ë¡œ ìˆ˜í–‰ë˜ë©°, ì´ë¥¼ í†µí•´ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ê³„ì†í•´ì„œ ê°œì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "7. **ëª¨ë¸ ë°°í¬**: ìµœì¢…ì ìœ¼ë¡œ ìµœì í™”ëœ ëª¨ë¸ì„ ì‹¤ì œ í™˜ê²½ì— ë°°í¬í•˜ì—¬ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ ë‹¨ê³„ì—ì„œëŠ” ëª¨ë¸ì´ ì•ˆì •ì ìœ¼ë¡œ ì‘ë™í•˜ëŠ”ì§€ ëª¨ë‹ˆí„°ë§í•˜ê³ , í•„ìš”ì— ë”°ë¼ ì¶”ê°€ì ì¸ ì—…ë°ì´íŠ¸ë‚˜ ìœ ì§€ ë³´ìˆ˜ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
      "\n",
      "ì´ëŸ¬í•œ ì¼ë ¨ì˜ ê³¼ì •ì„ í†µí•´ ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì€ ì£¼ì–´ì§„ ë¬¸ì œì— ëŒ€í•´ í•™ìŠµí•˜ê³ , ê·¸ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ëŠ¥ë ¥ì„ ê°–ì¶”ê²Œ ë©ë‹ˆë‹¤."
     ]
    }
   ],
   "source": [
    "# ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ì„ ìœ„í•œ ìš”ì²­\n",
    "try:\n",
    "    answer = chain2.stream({\"input\": \"ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ ìì„¸í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.\"})\n",
    "    # ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥\n",
    "    print(answer)\n",
    "\n",
    "    for token in answer:\n",
    "        # ìŠ¤íŠ¸ë¦¼ì—ì„œ ë°›ì€ ë°ì´í„°ì˜ ë‚´ìš©ì„ ì¶œë ¥í•©ë‹ˆë‹¤. ì¤„ë°”ê¿ˆ ì—†ì´ ì´ì–´ì„œ ì¶œë ¥í•˜ê³ , ë²„í¼ë¥¼ ì¦‰ì‹œ ë¹„ì›ë‹ˆë‹¤.\n",
    "        print(token, end=\"\", flush=True)\n",
    "except Exception as e:\n",
    "    print(f\"ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da0bfea",
   "metadata": {},
   "source": [
    "### Multi Chain\n",
    "* ì²« ë²ˆì§¸ Chainì˜ ì¶œë ¥ì´, ë‘ ë²ˆì§¸ Chainì˜ ì…ë ¥ì´ ëœë‹¤.\n",
    "* ë‘ ê°œì˜ Chainê³¼ Prompt + OutputParserë¥¼ LCELë¡œ ì—°ê²°í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "92c4cd0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x000001EDEF8C7F20> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001EDEF8C6ED0> root_client=<openai.OpenAI object at 0x000001EDEF8C53A0> root_async_client=<openai.AsyncOpenAI object at 0x000001EDEDA76030> model_name='meta-llama/llama-4-scout-17b-16e-instruct' temperature=0.7 model_kwargs={} openai_api_key=SecretStr('**********') openai_api_base='https://api.groq.com/openai/v1'\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Step 1: ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì¥ë¥´ì— ë”°ë¼ ì˜í™” ì¶”ì²œ\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} ì¥ë¥´ì—ì„œ ì¶”ì²œí•  ë§Œí•œ ì˜í™”ë¥¼ í•œ í¸ ì•Œë ¤ì£¼ì„¸ìš”.\")\n",
    "\n",
    "# Step 2: ì¶”ì²œëœ ì˜í™”ì˜ ì¤„ê±°ë¦¬ë¥¼ ìš”ì•½\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} ì¶”ì „í•œ ì˜í™”ì˜ ì œëª©ì„ ë¨¼ì € ì•Œë ¤ì£¼ì‹œê³ , ì¤„ì„ ë°”ê¾¸ì–´ì„œ ì˜í™”ì˜ ì¤„ê±°ë¦¬ë¥¼ 3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”.\")\n",
    "\n",
    "# OpenAI ëª¨ë¸ ì‚¬ìš©\n",
    "# Groq APIë¥¼ ì‚¬ìš©í•˜ëŠ” ChatOpenAI ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "print(llm)\n",
    "\n",
    "# ì²´ì¸ 1: ì˜í™” ì¶”ì²œ (ì…ë ¥: ì¥ë¥´ â†’ ì¶œë ¥: ì˜í™” ì œëª©)\n",
    "chain1 = prompt1 | llm | StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dc772051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The movie I recommend is **'ë·°í‹°í’€ ë§ˆì¸ë“œ'**.\n",
      "\n",
      "Here is a summary of the movie in three sentences:\n",
      "\n",
      "The film tells the story of John Nash, a brilliant mathematician who struggles with schizophrenia while studying at Princeton University. As Nash's mental health deteriorates, he faces numerous challenges and setbacks, but ultimately finds love, friendship, and a way to overcome his illness. Through its powerful portrayal of Nash's journey, the movie aims to break down stigmas surrounding mental illness and highlight the importance of human connection and resilience.\n"
     ]
    }
   ],
   "source": [
    "# ì²´ì¸ 2: ì¤„ê±°ë¦¬ ìš”ì•½ (ì…ë ¥: ì˜í™” ì œëª© â†’ ì¶œë ¥: ì¤„ê±°ë¦¬)\n",
    "try:\n",
    "    chain2 = (\n",
    "        {\"movie\": chain1}  # chain1ì˜ ì¶œë ¥ì„ movie ë³€ìˆ˜ë¡œ ì „ë‹¬\n",
    "        | prompt2\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    # ì‹¤í–‰: \"SF\" ì¥ë¥´ì˜ ì˜í™” ì¶”ì²œ ë° ì¤„ê±°ë¦¬ ìš”ì•½\n",
    "    response = chain2.invoke({\"genre\": \"Drama\"})\n",
    "    print(response)\n",
    "except Exception as e:\n",
    "    print(f\"ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a15574",
   "metadata": {},
   "source": [
    "### PromptTemplate ì—¬ëŸ¬ê°œ ì—°ê²°í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "da505839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
      "\n",
      "ChatGPTëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ë¡œ, ìˆ˜ì‹­ì–µ ê°œì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ì´ ëª¨ë¸ì€ ì¸í„°ë„·ì—ì„œ ìˆ˜ì§‘í•œ ëŒ€ê·œëª¨ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµí•˜ì—¬ ìì—°ì–´ ì²˜ë¦¬ ëŠ¥ë ¥ì„ ê°œë°œí•©ë‹ˆë‹¤. í•™ìŠµ ê³¼ì •ì—ì„œ ëª¨ë¸ì€ ì…ë ¥ëœ í…ìŠ¤íŠ¸ì— ëŒ€í•œ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ë„ë¡ í›ˆë ¨ë˜ë©°, ì´ë¥¼ í†µí•´ ëŒ€í™”ì™€ ê°™ì€ ìì—°ì–´ ìƒí˜¸ì‘ìš©ì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ChatGPT ëª¨ë¸ì˜ ì¥ì ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
      "\n",
      "* ìì—°ì–´ ì´í•´ ë° ìƒì„± ëŠ¥ë ¥\n",
      "* ëŒ€ê·œëª¨ ì§€ì‹ ë°ì´í„°ë² ì´ìŠ¤ì— ê¸°ë°˜í•œ ë‹µë³€ ì œê³µ\n",
      "* ë‹¤ì–‘í•œ ì£¼ì œ ë° ìƒí™©ì— ëŒ€í•œ ëŒ€í™” ì§€ì›\n",
      "* ë†’ì€ ìˆ˜ì¤€ì˜ ì–¸ì–´ ì´í•´ ë° ìƒì„± ëŠ¥ë ¥\n",
      "\n",
      "ChatGPT ëª¨ë¸ê³¼ ë¹„ìŠ·í•œ AI ëª¨ë¸ì€ ë‹¤ìŒê³¼ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "* LLaMA\n",
      "* PaLM\n",
      "* BERT\n",
      "* RoBERTa\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ {count} ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì„œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\"\n",
    "\n",
    "# PromptTemplate ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "# í…œí”Œë¦¿ì— ê°’ì„ ì±„ì›Œì„œ í”„ë¡¬í”„íŠ¸ë¥¼ ì™„ì„±\n",
    "filled_prompt = prompt_template.format(model_name=\"ChatGPT\", count=3)\n",
    "\n",
    "# ë¬¸ìì—´ í…œí”Œë¦¿ ê²°í•© (PromptTemplate + PromptTemplate + ë¬¸ìì—´)\n",
    "combined_prompt = (\n",
    "              prompt_template\n",
    "              + PromptTemplate.from_template(\"\\n\\n ê·¸ë¦¬ê³  {model_name} ëª¨ë¸ì˜ ì¥ì ì„ ìš”ì•½ ì •ë¦¬í•´ ì£¼ì„¸ìš”\")\n",
    "              + \"\\n\\n {model_name} ëª¨ë¸ê³¼ ë¹„ìŠ·í•œ AI ëª¨ë¸ì€ ì–´ë–¤ ê²ƒì´ ìˆë‚˜ìš”? ëª¨ë¸ëª…ì€ {language}ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\"\n",
    ")\n",
    "combined_prompt.format(model_name=\"ChatGPT\", count=3, language=\"ì˜ì–´\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "chain = combined_prompt | llm | StrOutputParser()\n",
    "response = chain.invoke({\"model_name\":\"ChatGPT\", \"count\":3, \"language\":\"ì˜ì–´\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f3ffe2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GPT-4 ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ 2 ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì„œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.', 'Gemma ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ 3 ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì„œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.', 'llama-4 ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ 4 ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì„œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.']\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ {count} ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì„œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\"\n",
    "\n",
    "# PromptTemplate ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "questions = [\n",
    "    {\"model_name\": \"GPT-4\", \"count\": 2},\n",
    "    {\"model_name\": \"Gemma\", \"count\": 3},\n",
    "    {\"model_name\": \"llama-4\", \"count\": 4},\n",
    "]\n",
    "\n",
    "# ì—¬ëŸ¬ ê°œì˜ í”„ë¡¬í”„íŠ¸ë¥¼ ë¯¸ë¦¬ ìƒì„±\n",
    "formatted_prompts = [prompt_template.format(**q) for q in questions]\n",
    "print(formatted_prompts)  # ë¯¸ë¦¬ ìƒì„±ëœ ì§ˆë¬¸ ëª©ë¡ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "69300835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='GPT-4 ëª¨ë¸ì€ ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ í•™ìŠµë˜ë©°, ìì—°ì–´ ì²˜ë¦¬ ì‘ì—…ì— íŠ¹í™”ëœ íŠ¸ëœìŠ¤í¬ë¨¸ ì•„í‚¤í…ì²˜ë¥¼ í™œìš©í•©ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ ì£¼ì–´ì§„ ë¬¸ë§¥ì„ ì´í•´í•˜ê³  ì ì ˆí•œ ì‘ë‹µì„ ìƒì„±í•˜ë„ë¡ í•™ìŠµë˜ë©°, ê°•í™” í•™ìŠµ ë° ì§€ë„ í•™ìŠµì„ í†µí•´ ì§€ì†ì ìœ¼ë¡œ ê°œì„ ë©ë‹ˆë‹¤.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 71, 'prompt_tokens': 30, 'total_tokens': 101, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.212888058, 'prompt_time': 0.002649579, 'completion_time': 0.140206777, 'total_time': 0.142856356}, 'model_name': 'meta-llama/llama-4-scout-17b-16e-instruct', 'system_fingerprint': 'fp_37da608fc1', 'id': 'chatcmpl-852b220a-9389-4d98-8062-3ee97fd5c66a', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--b52a3097-2d06-410f-b3e6-64724642391c-0' usage_metadata={'input_tokens': 30, 'output_tokens': 71, 'total_tokens': 101, 'input_token_details': {}, 'output_token_details': {}}\n",
      "content='GemmaëŠ” ì»´í“¨í„°ê°€ ìì—°ì–´ ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•˜ë„ë¡ íŠ¹ë³„íˆ ì„¤ê³„ëœ ì¸ê³µì§€ëŠ¥(AI) ì–¸ì–´ ëª¨ë¸ì…ë‹ˆë‹¤. ëŒ€ê·œëª¨ í…ìŠ¤íŠ¸ ë°ì´í„° ì„¸íŠ¸ì— ëŒ€í•´ í•™ìŠµë˜ì—ˆìœ¼ë©°, ì´ í•™ìŠµì„ í†µí•´ ì£¼ì–´ì§„ ë§¥ë½ì—ì„œ ë‹¤ìŒì— ì˜¤ëŠ” ë¬¸ì¥ì´ë‚˜ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ëŠ¥ë ¥ì„ ìŠµë“í–ˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ í•™ìŠµ ë•ë¶„ì— GemmaëŠ” ë‹¤ì–‘í•œ ìì—°ì–´ ì²˜ë¦¬ ì‘ì—…ì— í™œìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 76, 'prompt_tokens': 29, 'total_tokens': 105, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.33336086200000004, 'prompt_time': 0.003094952, 'completion_time': 0.151682232, 'total_time': 0.154777184}, 'model_name': 'meta-llama/llama-4-scout-17b-16e-instruct', 'system_fingerprint': 'fp_79da0e0073', 'id': 'chatcmpl-d00a4cd8-b0a6-4f30-bcf7-23a6e99ab5c2', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--74aac731-30d4-4b87-8a34-a0c1dce7996a-0' usage_metadata={'input_tokens': 29, 'output_tokens': 76, 'total_tokens': 105, 'input_token_details': {}, 'output_token_details': {}}\n",
      "content='llama-4 ëª¨ë¸ì€ ë©”íƒ€ì—ì„œ ê°œë°œí•œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì…ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ ë°©ëŒ€í•œ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµë˜ë©°, ì´ë¥¼ í†µí•´ ìì—°ì–´ ì²˜ë¦¬ ëŠ¥ë ¥ì„ ìŠµë“í•©ë‹ˆë‹¤. í•™ìŠµ ê³¼ì •ì—ì„œ ëª¨ë¸ì€ ì…ë ¥ëœ í…ìŠ¤íŠ¸ì˜ íŒ¨í„´ê³¼ êµ¬ì¡°ë¥¼ ë¶„ì„í•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒì— ë‚˜íƒ€ë‚  ë‹¨ì–´ ë˜ëŠ” ë¬¸ì¥ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì˜ˆì¸¡ê³¼ì •ì„ ë°˜ë³µí•˜ë©´ì„œ ëª¨ë¸ì€ ì–¸ì–´ì— ëŒ€í•œ ì´í•´ì™€ ìƒì„± ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ê²Œ ë©ë‹ˆë‹¤.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 85, 'prompt_tokens': 31, 'total_tokens': 116, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.27029388099999996, 'prompt_time': 0.003391917, 'completion_time': 0.169799579, 'total_time': 0.173191496}, 'model_name': 'meta-llama/llama-4-scout-17b-16e-instruct', 'system_fingerprint': 'fp_79da0e0073', 'id': 'chatcmpl-d3fe4145-d9ac-49ae-9c39-d5bf9a7ba699', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--ce8ae3d6-66aa-4078-880a-7ef41277ccb8-0' usage_metadata={'input_tokens': 31, 'output_tokens': 85, 'total_tokens': 116, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "for prompt in formatted_prompts:\n",
    "    response = llm.invoke(prompt) # AI Message íƒ€ì…\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec35fd96",
   "metadata": {},
   "source": [
    "### ChatMessagePromptTemplate\n",
    "* SystemMessagePrompt, HumanMessagePromptTemplate, AIMessagePromptTemplateë¥¼ ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6a411048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\n",
      "## ë”¥ëŸ¬ë‹ì˜ ì •ì˜\n",
      "\n",
      "ë”¥ëŸ¬ë‹ì€ ì¸ê³µì‹ ê²½ë§ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹ì˜ í•œ ë¶„ì•¼ì…ë‹ˆë‹¤. ì¸ê³µì‹ ê²½ë§ì€ ì¸ê°„ì˜ ë‡Œë¥¼ ëª¨ë°©í•œ êµ¬ì¡°ë¡œ, ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ê³  í•™ìŠµí•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤. ë”¥ëŸ¬ë‹ì€ ì´ëŸ¬í•œ ì¸ê³µì‹ ê²½ë§ì„ ê¹Šê²Œ ìŒ“ì•„ ì˜¬ë¦¼ìœ¼ë¡œì¨ ë³µì¡í•œ ë°ì´í„°ì™€ íŒ¨í„´ì„ í•™ìŠµí•˜ê³  ì˜ˆì¸¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "## ë”¥ëŸ¬ë‹ì˜ ì‘ë™ ì›ë¦¬\n",
      "\n",
      "ë”¥ëŸ¬ë‹ì€ ë‹¤ìŒê³¼ ê°™ì€ ë‹¨ê³„ë¥¼ ê±°ì³ ì‘ë™í•©ë‹ˆë‹¤.\n",
      "\n",
      "1. **ë°ì´í„° ìˆ˜ì§‘**: ë”¥ëŸ¬ë‹ ëª¨ë¸ì€ ëŒ€ëŸ‰ì˜ ë°ì´í„°ë¥¼ í•„ìš”ë¡œ í•©ë‹ˆë‹¤. ì´ ë°ì´í„°ëŠ” ì´ë¯¸ì§€, í…ìŠ¤íŠ¸, ì˜¤ë””ì˜¤ ë“± ë‹¤ì–‘í•œ í˜•íƒœì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "2. **ë°ì´í„° ì „ì²˜ë¦¬**: ìˆ˜ì§‘ëœ ë°ì´í„°ëŠ” ì „ì²˜ë¦¬ ê³¼ì •ì„ ê±°ì¹©ë‹ˆë‹¤. ì´ ê³¼ì •ì—ì„œëŠ” ë°ì´í„°ì˜ ì¡ìŒ ì œê±°, ì •ê·œí™”, ë³€í™˜ ë“±ì´ ìˆ˜í–‰ë©ë‹ˆë‹¤.\n",
      "3. **ëª¨ë¸ ì„¤ê³„**: ë”¥ëŸ¬ë‹ ëª¨ë¸ì€ ì¸ê³µì‹ ê²½ë§ì„ ê¸°ë°˜ìœ¼ë¡œ ì„¤ê³„ë©ë‹ˆë‹¤. ëª¨ë¸ì€ ì…ë ¥ì¸µ, ì€ë‹‰ì¸µ, ì¶œë ¥ì¸µìœ¼ë¡œ êµ¬ì„±ë˜ë©°, ê° ì¸µì€ ì—¬ëŸ¬ ê°œì˜ ë…¸ë“œë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.\n",
      "4. **í•™ìŠµ**: ëª¨ë¸ì€ í•™ìŠµ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµí•©ë‹ˆë‹¤. í•™ìŠµ ê³¼ì •ì—ì„œëŠ” ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ê°€ ì¡°ì •ë˜ë©°, ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ìµœì í™”ë©ë‹ˆë‹¤.\n",
      "5. **í‰ê°€**: í•™ìŠµëœ ëª¨ë¸ì€ í‰ê°€ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ í‰ê°€ë©ë‹ˆë‹¤. í‰ê°€ ê³¼ì •ì—ì„œëŠ” ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ì¸¡ì •ë˜ë©°, ëª¨ë¸ì˜ ì •í™•ë„ê°€ í™•ì¸ë©ë‹ˆë‹¤.\n",
      "\n",
      "## ë”¥ëŸ¬ë‹ì˜ íŠ¹ì§•\n",
      "\n",
      "ë”¥ëŸ¬ë‹ì€ ë‹¤ìŒê³¼ ê°™ì€ íŠ¹ì§•ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "* **ìë™í™”ëœ íŠ¹ì§• í•™ìŠµ**: ë”¥ëŸ¬ë‹ ëª¨ë¸ì€ ë°ì´í„°ë¡œë¶€í„° ìë™ìœ¼ë¡œ íŠ¹ì§•ì„ í•™ìŠµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ê¸°ì¡´ì˜ ë¨¸ì‹ ëŸ¬ë‹ ë°©ë²•ì—ì„œëŠ” ì–´ë ¤ì› ë˜ ì‘ì—…ì…ë‹ˆë‹¤.\n",
      "* **ëŒ€ëŸ‰ì˜ ë°ì´í„° ìš”êµ¬**: ë”¥ëŸ¬ë‹ ëª¨ë¸ì€ ëŒ€ëŸ‰ì˜ ë°ì´í„°ë¥¼ í•„ìš”ë¡œ í•©ë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ í•„ìš”í•©ë‹ˆë‹¤.\n",
      "* **ê³ ì„±ëŠ¥ ì»´í“¨íŒ… ìš”êµ¬**: ë”¥ëŸ¬ë‹ ëª¨ë¸ì€ ê³ ì„±ëŠ¥ ì»´í“¨íŒ…ì„ í•„ìš”ë¡œ í•©ë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ì˜ í•™ìŠµê³¼ í‰ê°€ë¥¼ ë¹ ë¥´ê²Œ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ í•„ìš”í•©ë‹ˆë‹¤.\n",
      "\n",
      "## ë”¥ëŸ¬ë‹ì˜ ì‘ìš© ë¶„ì•¼\n",
      "\n",
      "ë”¥ëŸ¬ë‹ì€ ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ ì‘ìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´,\n",
      "\n",
      "* **ì´ë¯¸ì§€ ì¸ì‹**: ë”¥ëŸ¬ë‹ì€ ì´ë¯¸ì§€ ì¸ì‹ ë¶„ì•¼ì—ì„œ ë„ë¦¬ ì‚¬ìš©ë©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì–¼êµ´ ì¸ì‹, ê°ì²´ ì¸ì‹, ì´ë¯¸ì§€ ë¶„ë¥˜ ë“±ì´ ìˆìŠµë‹ˆë‹¤.\n",
      "* **ìì—°ì–´ ì²˜ë¦¬**: ë”¥ëŸ¬ë‹ì€ ìì—°ì–´ ì²˜ë¦¬ ë¶„ì•¼ì—ì„œ ë„ë¦¬ ì‚¬ìš©ë©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì–¸ì–´ ë²ˆì—­, ê°ì • ë¶„ì„, í…ìŠ¤íŠ¸ ë¶„ë¥˜ ë“±ì´ ìˆìŠµë‹ˆë‹¤.\n",
      "* **ìŒì„± ì¸ì‹**: ë”›ëŸ¬ë‹ì€ ìŒì„± ì¸ì‹ ë¶„ì•¼ì—ì„œ ë„ë¦¬ ì‚¬ìš©ë©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ìŒì„± ë²ˆì—­, ìŒì„± ì¸ì‹, ìŒì•… ë¶„ë¥˜ ë“±ì´ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "## ê²°ë¡ \n",
      "\n",
      "ë”¥ëŸ¬ë‹ì€ ì¸ê³µì‹ ê²½ë§ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹ì˜ í•œ ë¶„ì•¼ì…ë‹ˆë‹¤. ë”¥ëŸ¬ë‹ì€ ë³µì¡í•œ ë°ì´í„°ì™€ íŒ¨í„´ì„ í•™ìŠµí•˜ê³  ì˜ˆì¸¡í•  ìˆ˜ ìˆìœ¼ë©°, ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ ì‘ìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ê°œë³„ ë©”ì‹œì§€ í…œí”Œë¦¿ ì •ì˜\n",
    "system_message = SystemMessagePromptTemplate.from_template(\n",
    "    \"ë‹¹ì‹ ì€ {topic} ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ëª…í™•í•˜ê³  ìì„¸í•˜ê²Œ ì„¤ëª…í•´ ì£¼ì„¸ìš”.\"\n",
    ")\n",
    "user_message = HumanMessagePromptTemplate.from_template(\n",
    "    \"{question}\"\n",
    ")\n",
    "ai_message = AIMessagePromptTemplate.from_template(\n",
    "    \"{topic}ì— ëŒ€í•œ ì˜ˆì‹œ ë‹µì…ë‹ˆë‹¤.\"\n",
    ")\n",
    "\n",
    "# ChatPromptTemplateë¡œ ë©”ì‹œì§€ë“¤ì„ ë¬¶ê¸°\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_message,\n",
    "    user_message,\n",
    "    ai_message\n",
    "])\n",
    "\n",
    "# ë©”ì‹œì§€ ìƒì„±\n",
    "messages = chat_prompt.format_messages(topic=\"AI\", question=\"ë”¥ëŸ¬ë‹ì€ ë¬´ì—‡ì¸ê°€ìš”??\")\n",
    "\n",
    "# LLM í˜¸ì¶œ\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f270c1a",
   "metadata": {},
   "source": [
    "### FewShotPromptTemplate\n",
    "* ì˜ˆì‹œë¥¼ ì œê³µí•˜ëŠ” í”„ë¡¬í”„íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "98329813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### íƒœì–‘ê³„ì˜ í–‰ì„±\n",
      "1. **ìˆ˜ì„±**: íƒœì–‘ê³¼ ê°€ì¥ ê°€ê¹Œìš´ í–‰ì„±ìœ¼ë¡œ, ë§¤ìš° ì‘ê³  ì˜¨ë„ê°€ ê·¹ì‹¬í•˜ê²Œ ë³€í•©ë‹ˆë‹¤.\n",
      "2. **ê¸ˆì„±**: ë‘êº¼ìš´ ëŒ€ê¸°ë¡œ ì¸í•´ ê·¹ì‹¬í•œ ì˜¨ì‹¤ íš¨ê³¼ê°€ ìˆìŠµë‹ˆë‹¤.\n",
      "3. **ì§€êµ¬**: ìƒëª…ì²´ê°€ ì¡´ì¬í•˜ëŠ” ìœ ì¼í•œ í–‰ì„±ì…ë‹ˆë‹¤.\n",
      "4. **í™”ì„±**: ë¶‰ì€ìƒ‰ì´ë©°, ê³¼ê±°ì—ëŠ” ë¬¼ì´ ì¡´ì¬í–ˆì„ ê²ƒìœ¼ë¡œ ì¶”ì •ë©ë‹ˆë‹¤.\n",
      "5. **ëª©ì„±**: íƒœì–‘ê³„ì—ì„œ ê°€ì¥ í° í–‰ì„±ìœ¼ë¡œ, ê°€ìŠ¤ í–‰ì„±ì…ë‹ˆë‹¤.\n",
      "6. **í† ì„±**: ì•„ë¦„ë‹¤ìš´ ê³ ë¦¬ë¥¼ ê°€ì§€ê³  ìˆëŠ” ê°€ìŠ¤ í–‰ì„±ì…ë‹ˆë‹¤.\n",
      "7. **ì²œì™•ì„±**: ìì „ì¶•ì´ ê¸°ìš¸ì–´ì ¸ ìˆì–´ ê·¹ë‹¨ì ì¸ ê³„ì ˆ ë³€í™”ë¥¼ ê²ªìŠµë‹ˆë‹¤.\n",
      "8. **í•´ì™•ì„±**: íƒœì–‘ê³„ì—ì„œ ê°€ì¥ ë¨¼ í–‰ì„±ìœ¼ë¡œ, ê°•í•œ ë°”ëŒì´ ë¶ˆê³  ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"ë‰´í„´ì˜ ìš´ë™ ë²•ì¹™ì„ ìš”ì•½í•´ ì£¼ì„¸ìš”.\",\n",
    "        \"output\": \"\"\"### ë‰´í„´ì˜ ìš´ë™ ë²•ì¹™\n",
    "1. **ê´€ì„±ì˜ ë²•ì¹™**: í˜ì´ ì‘ìš©í•˜ì§€ ì•Šìœ¼ë©´ ë¬¼ì²´ëŠ” ê³„ì† ê°™ì€ ìƒíƒœë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.\n",
    "2. **ê°€ì†ë„ì˜ ë²•ì¹™**: ë¬¼ì²´ì— í˜ì´ ì‘ìš©í•˜ë©´, í˜ê³¼ ì§ˆëŸ‰ì— ë”°ë¼ ê°€ì†ë„ê°€ ê²°ì •ë©ë‹ˆë‹¤.\n",
    "3. **ì‘ìš©-ë°˜ì‘ìš© ë²•ì¹™**: ëª¨ë“  í˜ì—ëŠ” í¬ê¸°ê°€ ê°™ê³  ë°©í–¥ì´ ë°˜ëŒ€ì¸ í˜ì´ ì‘ìš©í•©ë‹ˆë‹¤.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"ì§€êµ¬ì˜ ëŒ€ê¸° êµ¬ì„± ìš”ì†Œë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.\",\n",
    "        \"output\": \"\"\"### ì§€êµ¬ ëŒ€ê¸°ì˜ êµ¬ì„±\n",
    "- **ì§ˆì†Œ (78%)**: ëŒ€ê¸°ì˜ ëŒ€ë¶€ë¶„ì„ ì°¨ì§€í•©ë‹ˆë‹¤.\n",
    "- **ì‚°ì†Œ (21%)**: ìƒëª…ì²´ê°€ í˜¸í¡í•˜ëŠ” ë° í•„ìš”í•©ë‹ˆë‹¤.\n",
    "- **ì•„ë¥´ê³¤ (0.93%)**: ë°˜ì‘ì„±ì´ ë‚®ì€ ê¸°ì²´ì…ë‹ˆë‹¤.\n",
    "- **ì´ì‚°í™”íƒ„ì†Œ (0.04%)**: ê´‘í•©ì„± ë° ì˜¨ì‹¤ íš¨ê³¼ì— ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# ì˜ˆì œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# FewShotChatMessagePromptTemplate ì ìš©\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "# ìµœì¢… í”„ë¡¬í”„íŠ¸ êµ¬ì„±\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"ë‹¹ì‹ ì€ ì´ˆë“±í•™ìƒë„ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì‰½ê²Œ ì„¤ëª…í•˜ëŠ” ê³¼í•™ êµìœ¡ìì…ë‹ˆë‹¤.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ëª¨ë¸ ìƒì„± ë° ì²´ì¸ êµ¬ì„±\n",
    "model = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "chain = final_prompt | model\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "result = chain.invoke({\"input\": \"íƒœì–‘ê³„ì˜ í–‰ì„±ë“¤ì„ ê°„ëµíˆ ì •ë¦¬í•´ ì£¼ì„¸ìš”.\"})\n",
    "#result = chain.invoke({\"input\": \"ì–‘ì ì–½í˜ì´ ë¬´ì—‡ì¸ê°€ìš”?\"})\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee99c1bc",
   "metadata": {},
   "source": [
    "### PartialPromptTemplate\n",
    "* í”„ë¡¬í”„íŠ¸ ì…ë ¥ ê°’ì— í•¨ìˆ˜ í˜¸ì¶œì´ë‚˜ ì™¸ë¶€ APIë¥¼ í˜¸ì¶œí•œ ë™ì ì¸ ê°’ì„ ëŒ€ì…í•  ìˆ˜ ìˆìŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c21714d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¹ í”„ë¡¬í”„íŠ¸: input_variables=['season'] input_types={} partial_variables={} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['season'], input_types={}, partial_variables={}, template='{season}ì— ì¼ì–´ë‚˜ëŠ” ëŒ€í‘œì ì¸ ì§€êµ¬ê³¼í•™ í˜„ìƒ 3ê°€ì§€ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.ê° í˜„ìƒì— ëŒ€í•´ ê°„ë‹¨í•œ ì„¤ëª…ì„ í¬í•¨í•´ì£¼ì„¸ìš”.'), additional_kwargs={})]\n",
      "ğŸ”¹ ëª¨ë¸ ì‘ë‹µ: ê²¨ìš¸ì— ë°œìƒí•˜ëŠ” ìì—° í˜„ìƒ :\n",
      " 1.  **ë¶ê·¹ê´‘(ì˜¤ë¡œë¼)**: ë¶ê·¹ê´‘ì€ íƒœì–‘ì˜ íƒœì–‘í’ì´ ì§€êµ¬ì˜ ìê¸°ì¥ì— ë‹¿ì•„ ë°œìƒí•©ë‹ˆë‹¤. íƒœì–‘í’ì˜ ì „í•˜ ì…ìê°€ ì§€êµ¬ì˜ ìê¸°ì¥ì— ì˜í•´ ë°©í–¥ì„ ë°”ê¾¸ì–´ ëŒ€ê¸°ê¶Œê³¼ ì¶©ëŒí•˜ë©´ì„œ ë°œìƒë˜ëŠ” ë¹›ì…ë‹ˆë‹¤. ë¶ê·¹ê´‘ì€ ì£¼ë¡œ ë¶ê·¹ ì§€ì—­ì—ì„œ ë³¼ ìˆ˜ ìˆìœ¼ë©°, íƒœì–‘í’ì´ ê°•í• ìˆ˜ë¡ ë” ë°ê³  í™”ë ¤í•˜ê²Œ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.\n",
      "\n",
      "2.  **ë¹™í•˜ í˜•ì„±**: ê²¨ìš¸ì´ ë˜ë©´ ê¸°ì˜¨ì´ ë‚®ì•„ì§€ë©´ì„œ ëˆˆê³¼ ë¹„ê°€ ì–¼ì–´ë¶™ì–´ ë¹™í•˜ê°€ í˜•ì„±ë©ë‹ˆë‹¤. ë¹™í•˜ëŠ” ì§€êµ¬ì˜ ê·¹ì§€ë°©ì—ì„œ ë°œê²¬ë˜ë©°, ë¹™í•˜ì˜ í˜•ì„± ê³¼ì •ì€ ìˆ˜ì²œ ë…„ì— ê±¸ì³ ì¼ì–´ë‚˜ê³  ìˆìŠµë‹ˆë‹¤. ë¹™í•˜ëŠ” ì§€êµ¬ì˜ ê¸°í›„ ë³€í™”ì— ë¯¼ê°í•˜ê²Œ ë°˜ì‘í•˜ê¸° ë•Œë¬¸ì— ê¸°í›„ ì—°êµ¬ì— ì¤‘ìš”í•œ ì§€í‘œì…ë‹ˆë‹¤.\n",
      "\n",
      "3.  **ê·¹ì•¼ í˜„ìƒ**: ê·¹ì•¼ í˜„ìƒì€ ë¶ê·¹ê³¼ ë‚¨ê·¹ ì§€ì—­ì—ì„œ ê²¨ìš¸ì— ì¼ì–´ë‚˜ëŠ” í˜„ìƒìœ¼ë¡œ, íƒœì–‘ì´ í•˜ë£¨ ì¢…ì¼ ì§€í‰ì„  ì•„ë˜ì— ë¨¸ë¬¼ëŸ¬ ìˆì–´ ë‚®ì´ ì „í˜€ ì—†ëŠ” í˜„ìƒì„ ë§í•©ë‹ˆë‹¤. ì´ ê¸°ê°„ ë™ì•ˆì—ëŠ” íƒœì–‘ì´ ëœ¨ì§€ ì•Šê¸° ë•Œë¬¸ì— ê·¹ì§€ë°©ì—ì„œëŠ” ë°¤ë§Œ ì§€ì†ë©ë‹ˆë‹¤. ê·¹ì•¼ í˜„ìƒì€ ë¶ê·¹ê³¼ ë‚¨ê·¹ì—ì„œ ê°ê° 6ê°œì›”ì”© ë°œìƒí•˜ë©°, ì´ ê¸°ê°„ ë™ì•ˆì—ëŠ” ë°¤ì´ ì§€ì†ë©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# ê³„ì ˆì„ ê²°ì •í•˜ëŠ” í•¨ìˆ˜ (ë‚¨ë°˜êµ¬/ë¶ë°˜êµ¬ ê³ ë ¤)\n",
    "def get_current_season(hemisphere=\"north\"):\n",
    "    month = datetime.now().month\n",
    "    \n",
    "    if hemisphere == \"north\":  # ë¶ë°˜êµ¬ (ê¸°ë³¸ê°’)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"ë´„\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"ì—¬ë¦„\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"ê°€ì„\"\n",
    "        else:\n",
    "            return \"ê²¨ìš¸\"\n",
    "    else:  # ë‚¨ë°˜êµ¬ (ê³„ì ˆ ë°˜ëŒ€)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"ê°€ì„\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"ê²¨ìš¸\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"ë´„\"\n",
    "        else:\n",
    "            return \"ì—¬ë¦„\"\n",
    "\n",
    "\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜ (ë¶€ë¶„ ë³€ìˆ˜ ì ìš©)\n",
    "# prompt = PromptTemplate(\n",
    "#     template=\"{season}ì— ì¼ì–´ë‚˜ëŠ” ëŒ€í‘œì ì¸ ì§€êµ¬ê³¼í•™ í˜„ìƒì€ {phenomenon}ì…ë‹ˆë‹¤.\",\n",
    "#     input_variables=[\"phenomenon\"],  # ì‚¬ìš©ì ì…ë ¥ í•„ìš”\n",
    "#     partial_variables={\"season\": get_current_season()}  # ë™ì ìœ¼ë¡œ ê³„ì ˆ ê°’ í• ë‹¹\n",
    "# )\n",
    "\n",
    "season = get_current_season(\"south\")\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"{season}ì— ì¼ì–´ë‚˜ëŠ” ëŒ€í‘œì ì¸ ì§€êµ¬ê³¼í•™ í˜„ìƒ 3ê°€ì§€ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.\"\n",
    "    \"ê° í˜„ìƒì— ëŒ€í•´ ê°„ë‹¨í•œ ì„¤ëª…ì„ í¬í•¨í•´ì£¼ì„¸ìš”.\"\n",
    ")\n",
    "\n",
    "# OpenAI ëª¨ë¸ ì´ˆê¸°í™”\n",
    "model = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "chain = (\n",
    "    {\"season\": lambda x: season} |\n",
    "    prompt |\n",
    "    model |\n",
    "    StrOutputParser()\n",
    "\n",
    ")\n",
    "# íŠ¹ì • ê³„ì ˆì˜ í˜„ìƒ ì§ˆì˜\n",
    "result = chain.invoke({})\n",
    "\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(f\"ğŸ”¹ í”„ë¡¬í”„íŠ¸: {prompt}\")\n",
    "print(f\"ğŸ”¹ ëª¨ë¸ ì‘ë‹µ: {season}ì— ë°œìƒí•˜ëŠ” ìì—° í˜„ìƒ :\\n {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cc59ea9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=[] input_types={} partial_variables={'info': '1ë‹¬ëŸ¬ = 1359.26ì›'} template='í˜„ì¬ {info} ê¸°ì¤€ìœ¼ë¡œ í™˜ìœ¨ ì •ë³´ë¥¼ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤. í˜„ì¬ í™˜ìœ¨ì„ ê¸°ì¤€ìœ¼ë¡œ í•œêµ­ ê²½ì œ ë¯¸ì¹˜ëŠ” ì˜í–¥ ë° í–¥í›„ì— í™˜ìœ¨ì˜ˆìƒê°’ì— ëŒ€í•œ ë¶„ì„ì„ ì œê³µí•´ ì£¼ì„¸ìš”.'\n",
      "ğŸ”¹ í”„ë¡¬í”„íŠ¸: í˜„ì¬ 1ë‹¬ëŸ¬ = 1359.26ì› ê¸°ì¤€ìœ¼ë¡œ í™˜ìœ¨ ì •ë³´ë¥¼ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤. í˜„ì¬ í™˜ìœ¨ì„ ê¸°ì¤€ìœ¼ë¡œ í•œêµ­ ê²½ì œ ë¯¸ì¹˜ëŠ” ì˜í–¥ ë° í–¥í›„ì— í™˜ìœ¨ì˜ˆìƒê°’ì— ëŒ€í•œ ë¶„ì„ì„ ì œê³µí•´ ì£¼ì„¸ìš”.\n",
      "ğŸ”¹ ëª¨ë¸ ì‘ë‹µ: í˜„ì¬ í™˜ìœ¨(1ë‹¬ëŸ¬ = 1359.26ì›)ì€ í•œêµ­ ê²½ì œì— ì—¬ëŸ¬ ê°€ì§€ ì˜í–¥ì„ ë¯¸ì¹˜ê³  ìˆìŠµë‹ˆë‹¤. ìš°ì„ , ë†’ì€ í™˜ìœ¨ì€ ìˆ˜ì¶œ ì¤‘ì‹¬ì˜ í•œêµ­ ê²½ì œì— ê¸ì •ì ì¸ ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
      "\n",
      "1. **ìˆ˜ì¶œ ì¦ê°€**: ë†’ì€ í™˜ìœ¨ì€ í•œêµ­ì˜ ìˆ˜ì¶œ ìƒí’ˆ ê°€ê²©ì„ ë‚®ì¶”ì–´ í•´ì™¸ ì‹œì¥ì—ì„œ ê²½ìŸë ¥ì„ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ìë™ì°¨, ë°˜ë„ì²´, ì² ê°• ë“± ì£¼ìš” ìˆ˜ì¶œ í’ˆëª©ì˜ ê°€ê²© ê²½ìŸë ¥ì„ ê°•í™”í•˜ì—¬ ìˆ˜ì¶œëŸ‰ì„ ì¦ê°€ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìˆ˜ì¶œ ì¦ê°€ëŠ” ë¬´ì—­ ìˆ˜ì§€ ê°œì„ ê³¼ ì™¸í™” ìˆ˜ì… ì¦ê°€ë¡œ ì´ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "2. **ë¬¼ê°€ ìƒìŠ¹**: ë°˜ë©´, ë†’ì€ í™˜ìœ¨ì€ ìˆ˜ì… ë¬¼ê°€ë¥¼ ìƒìŠ¹ì‹œì¼œ êµ­ë‚´ ë¬¼ê°€ ìƒìŠ¹ ì••ë ¥ì„ ê°€ì¤‘ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì›ìì¬, ì—ë„ˆì§€, ì‹í’ˆ ë“± ìˆ˜ì… ì˜ì¡´ë„ê°€ ë†’ì€ í’ˆëª©ë“¤ì˜ ê°€ê²©ì´ ìƒìŠ¹í•˜ë©´, ì´ëŠ” ê³§ êµ­ë‚´ ì†Œë¹„ì ë¬¼ê°€ ìƒìŠ¹ìœ¼ë¡œ ì´ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ê°€ê³„ì˜ êµ¬ë§¤ë ¥ì„ ê°ì†Œì‹œí‚¤ê³ , ì „ë°˜ì ì¸ ê²½ì œ ë¶ˆì•ˆì„ ì•¼ê¸°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "3. **ê¸°ì—… ìˆ˜ìµì„±**: ë†’ì€ í™˜ìœ¨ì€ ìˆ˜ì¶œ ë¹„ì¤‘ì´ í° ê¸°ì—…ë“¤ì˜ ìˆ˜ìµì„±ì„ ê°œì„ í•  ìˆ˜ ìˆì§€ë§Œ, ìˆ˜ì… ì›ìì¬ ê°€ê²© ìƒìŠ¹ìœ¼ë¡œ ì¸í•´ ê¸°ì—…ë“¤ì˜ ë¹„ìš© ë¶€ë‹´ì´ ì¦ê°€í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ, ìˆ˜ì… ì›ìì¬ì— ì˜ì¡´ë„ê°€ ë†’ì€ ì¤‘ì†Œê¸°ì—…ì´ë‚˜ íŠ¹ì • ì‚°ì—…ì—ì„œëŠ” ë¹„ìš© ì¦ê°€ë¡œ ì¸í•œ ìˆ˜ìµì„± ì•…í™”ê°€ ìš°ë ¤ë©ë‹ˆë‹¤.\n",
      "\n",
      "4. **ê¸ˆìœµ ì‹œì¥**: ì™¸í™˜ ì‹œì¥ì—ì„œ ì›í™” ê°€ì¹˜ê°€ ë‚®ì•„ì§€ë©´, ì™¸êµ­ì¸ íˆ¬ììì˜ êµ­ë‚´ ì£¼ì‹ ë° ì±„ê¶Œ ì‹œì¥ íˆ¬ìì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì›í™” ê°€ì¹˜ í•˜ë½ì€ ì™¸êµ­ì¸ì—ê²Œ êµ­ë‚´ ìì‚°ì˜ ë§¤ë ¥ì„ ê°ì†Œì‹œí‚¬ ìˆ˜ ìˆì–´, ìë³¸ ìœ ì¶œì…ì— ë³€ë™ì„±ì´ ì¦ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "í–¥í›„ í™˜ìœ¨ ì˜ˆìƒê°’ì— ëŒ€í•œ ë¶„ì„ì€ ì—¬ëŸ¬ ê°€ì§€ ìš”ì¸ì— ì˜í•´ ì¢Œìš°ë˜ë©°, ì´ëŠ” ë§¤ìš° ë³µì¡í•˜ê³  ë³€ë™ì„±ì´ í¬ë¯€ë¡œ ì •í™•íˆ ì˜ˆì¸¡í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ í˜„ì¬ ìƒí™©ì„ ë°”íƒ•ìœ¼ë¡œ í•œ ëª‡ ê°€ì§€ ì˜ˆì¸¡ ìš”ì¸ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
      "\n",
      "- **ê¸€ë¡œë²Œ ê²½ì œ ìƒí™©**: ë¯¸êµ­ì„ ë¹„ë¡¯í•œ ì£¼ìš”êµ­ì˜ ê²½ì œ ìƒí™©, ê¸ˆë¦¬ ë³€ë™, ì¸í”Œë ˆì´ì…˜ ë“±ì´ í™˜ìœ¨ì— í° ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤. \n",
      "- **í•œêµ­ì˜ ê²½ì œ ì„±ì¥**: í•œêµ­ì˜ ê²½ì œ ì„±ì¥ë¥ , ë¬´ì—­ ìˆ˜ì§€, ë¬¼ê°€ ìƒìŠ¹ë¥  ë“±ì´ ì›í™” ê°€ì¹˜ì— ì˜í–¥ì„ ì¤ë‹ˆë‹¤.\n",
      "- **ì •ì±… ë³€í™”**: ì •ë¶€ì™€ í•œêµ­ì€í–‰ì˜ ê²½ì œ ì •ì±…, íŠ¹íˆ ê¸ˆë¦¬ ì •ì±…ì´ë‚˜ ì™¸í™˜ ì‹œì¥ì— ëŒ€í•œ ê°œì… ë“±ì´ í™˜ìœ¨ì— ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "í™˜ìœ¨ì€ ì •ì¹˜, ê²½ì œ, ì‚¬íšŒ ë“± ë‹¤ì–‘í•œ ë³€ìˆ˜ì— ì˜í•´ ë³€ë™í•˜ë¯€ë¡œ, ì „ë¬¸ê°€ë“¤ì˜ ë¶„ì„ê³¼ ê²½ì œ ì§€í‘œ ë“±ì„ ì£¼ì˜ ê¹Šê²Œ ì‚´í´ë³´ì•„ì•¼ í•©ë‹ˆë‹¤. ë˜í•œ, ì§€ì •í•™ì  ë¦¬ìŠ¤í¬ë‚˜ ì˜ˆìƒì¹˜ ëª»í•œ ê¸€ë¡œë²Œ ê²½ì œ ì´ë²¤íŠ¸ ë°œìƒ ì‹œ í™˜ìœ¨ ë³€ë™ì„±ì´ í¬ê²Œ ì¦ê°€í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ì§€ì†ì ì¸ ëª¨ë‹ˆí„°ë§ì´ í•„ìš”í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ì‹¤ì‹œê°„ í™˜ìœ¨ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜\n",
    "def get_exchange_rate():\n",
    "    response = requests.get(\"https://api.exchangerate-api.com/v4/latest/USD\")\n",
    "    data = response.json()\n",
    "    return f\"1ë‹¬ëŸ¬ = {data['rates']['KRW']}ì›\"\n",
    "\n",
    "# {info} ë³€ìˆ˜ì— APIì—ì„œ ë°›ì€ í™˜ìœ¨ ì •ë³´ë¥¼ ë™ì ìœ¼ë¡œ ë°˜ì˜\n",
    "prompt = PromptTemplate(\n",
    "    template=\"í˜„ì¬ {info} ê¸°ì¤€ìœ¼ë¡œ í™˜ìœ¨ ì •ë³´ë¥¼ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤. í˜„ì¬ í™˜ìœ¨ì„ ê¸°ì¤€ìœ¼ë¡œ í•œêµ­ ê²½ì œ ë¯¸ì¹˜ëŠ” ì˜í–¥ ë° í–¥í›„ì— í™˜ìœ¨ì˜ˆìƒê°’ì— ëŒ€í•œ ë¶„ì„ì„ ì œê³µí•´ ì£¼ì„¸ìš”.\",\n",
    "    input_variables=[],  # ì‚¬ìš©ì ì…ë ¥ ì—†ìŒ\n",
    "    partial_variables={\"info\": get_exchange_rate()}  # APIì—ì„œ ê°€ì ¸ì˜¨ ë°ì´í„° ìë™ ë°˜ì˜\n",
    ")\n",
    "\n",
    "print(prompt)\n",
    "\n",
    "# LLM ëª¨ë¸ ì„¤ì • (GPT-4o-mini ì‚¬ìš©)\n",
    "model = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# ëª¨ë¸ì— í”„ë¡¬í”„íŠ¸ ì „ë‹¬ ë° ì‘ë‹µ ë°›ê¸°\n",
    "response = model.invoke(prompt.format())\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\"ğŸ”¹ í”„ë¡¬í”„íŠ¸:\", prompt.format())\n",
    "print(\"ğŸ”¹ ëª¨ë¸ ì‘ë‹µ:\", response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
