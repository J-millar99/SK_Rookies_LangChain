{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "402b0c98",
   "metadata": {},
   "source": [
    "### CommaSeparatedListOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "200f57d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b35b1b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['subject'], input_types={}, partial_variables={'format_instructions': 'Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`'}, template='List five {subject}.\\n{format_instructions}')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "import csv\n",
    "\n",
    "# ì½¤ë§ˆë¡œ êµ¬ë¶„ëœ ë¦¬ìŠ¤íŠ¸ ì¶œë ¥ íŒŒì„œ ì´ˆê¸°í™”\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "# ì¶œë ¥ í˜•ì‹ ì§€ì¹¨ ê°€ì ¸ì˜¤ê¸°\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •\n",
    "prompt = PromptTemplate(\n",
    "    template=\"List five {subject}.\\n{format_instructions}\",\n",
    "    input_variables=[\"subject\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7aceb6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AI ê´€ë ¨ ê¸°ìˆ  ëª©ë¡:\n",
      "['Machine Learning', 'Deep Learning', 'Natural Language Processing', 'Computer Vision', 'Robotics']\n",
      " './data/ai_technologies.csv' íŒŒì¼ë¡œ ì €ì¥ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# OpenAI ëª¨ë¸ ì„¤ì •\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸, ëª¨ë¸, ì¶œë ¥ íŒŒì„œë¥¼ ì—°ê²°í•˜ì—¬ ì²´ì¸ ìƒì„±\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "# \"AI ê´€ë ¨ ê¸°ìˆ \"ì— ëŒ€í•œ ì²´ì¸ í˜¸ì¶œ ì‹¤í–‰\n",
    "result = chain.invoke({\"subject\": \"AI ê´€ë ¨ ê¸°ìˆ \"})\n",
    "\n",
    "# ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ë¦¬ìŠ¤íŠ¸ ì¶œë ¥\n",
    "print(\" AI ê´€ë ¨ ê¸°ìˆ  ëª©ë¡:\")\n",
    "print(result)\n",
    "\n",
    "# ê²°ê³¼ í™œìš© ì˜ˆì‹œ: CSV íŒŒì¼ë¡œ ì €ì¥\n",
    "csv_filename = \"./data/ai_technologies.csv\"\n",
    "with open(csv_filename, \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"AI ê¸°ìˆ \"])  # í—¤ë” ì¶”ê°€\n",
    "    for item in result:\n",
    "        writer.writerow([item])\n",
    "\n",
    "print(f\" '{csv_filename}' íŒŒì¼ë¡œ ì €ì¥ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6503862",
   "metadata": {},
   "source": [
    "### JsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd4629cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "import json\n",
    "\n",
    "# JSON ì¶œë ¥ íŒŒì„œ ì´ˆê¸°í™”\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"ë‹¹ì‹ ì€ ê³¼í•™ ë¶„ì•¼ ì „ë¬¸ê°€ AIì…ë‹ˆë‹¤. ì§ˆë¬¸ì— ëŒ€í•´ ì²´ê³„ì ì´ê³  ê°„ê²°í•œ ë‹µë³€ì„ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•˜ì„¸ìš”.\"),\n",
    "        (\"user\", \"#Format: {format_instructions}\\n\\n#Question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# JSON ì¶œë ¥ í˜•ì‹ ì§€ì¹¨ì„ í”„ë¡¬í”„íŠ¸ì— ì ìš©\n",
    "prompt = prompt.partial(format_instructions=parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f28f3a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"mission_name\": \"ë‰´í˜¸ë¼ì´ì¦ŒìŠ¤(New Horizons)\",\n",
      "        \"goal\": \"ëª…ì™•ì„± ë° ì¹´ì´í¼ ë²¨íŠ¸ íƒì‚¬\",\n",
      "        \"agency\": \"ë‚˜ì‚¬(NASA)\"\n",
      "    },\n",
      "    {\n",
      "        \"mission_name\": \"í™”ì„± íƒì‚¬ì„  íë¦¬ì˜¤ì‹œí‹°(Curiosity Rover)\",\n",
      "        \"goal\": \"í™”ì„± í‘œë©´ íƒì‚¬ ë° ìƒëª…ì²´ ì¡´ì¬ ì—¬ë¶€ ì¡°ì‚¬\",\n",
      "        \"agency\": \"ë‚˜ì‚¬(NASA)\"\n",
      "    },\n",
      "    {\n",
      "        \"mission_name\": \"ì°½ì–´ 4í˜¸(Chang'e 4)\",\n",
      "        \"goal\": \"ë‹¬ ë’·ë©´ íƒì‚¬\",\n",
      "        \"agency\": \"ì¤‘êµ­ êµ­ê°€ìš°ì£¼êµ­(CNSA)\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# OpenAI ëª¨ë¸ ì„¤ì •\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "# í”„ë¡¬í”„íŠ¸, ëª¨ë¸, ì¶œë ¥ íŒŒì„œë¥¼ ì—°ê²°í•˜ëŠ” ì²´ì¸ ìƒì„±\n",
    "chain = prompt | model | parser\n",
    "\n",
    "# ì§ˆë¬¸ ì„¤ì • (ìš°ì£¼ íƒì‚¬ ê´€ë ¨ ì§ˆë¬¸)\n",
    "question = \"ìµœê·¼ 10ë…„ê°„ ì§„í–‰ëœ ì£¼ìš” ìš°ì£¼ íƒì‚¬ ë¯¸ì…˜ 3ê°€ì§€ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”. \\\n",
    "ê° ë¯¸ì…˜ì˜ ì´ë¦„ì€ `mission_name`ì—, ëª©í‘œëŠ” `goal`ì—, ì£¼ê´€ ê¸°ê´€ì€ `agency`ì— ë‹´ì•„ ì£¼ì„¸ìš”.\"\n",
    "\n",
    "# ì²´ì¸ ì‹¤í–‰ ë° JSON ì‘ë‹µ ë°›ê¸°\n",
    "response = chain.invoke({\"question\": question})\n",
    "\n",
    "# JSON ë°ì´í„° ì¶œë ¥\n",
    "print(json.dumps(response, indent=4, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c67630b",
   "metadata": {},
   "source": [
    "### PandasDataFrameOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd4439e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Format Instructions:\n",
      " The output should be formatted as a string as the operation, followed by a colon, followed by the column or row to be queried on, followed by optional array parameters.\n",
      "1. The column names are limited to the possible columns below.\n",
      "2. Arrays must either be a comma-separated list of numbers formatted as [1,3,5], or it must be in range of numbers formatted as [0..4].\n",
      "3. Remember that arrays are optional and not necessarily required.\n",
      "4. If the column is not in the possible columns or the operation is not a valid Pandas DataFrame operation, return why it is invalid as a sentence starting with either \"Invalid column\" or \"Invalid operation\".\n",
      "\n",
      "As an example, for the formats:\n",
      "1. String \"column:num_legs\" is a well-formatted instance which gets the column num_legs, where num_legs is a possible column.\n",
      "2. String \"row:1\" is a well-formatted instance which gets row 1.\n",
      "3. String \"column:num_legs[1,2]\" is a well-formatted instance which gets the column num_legs for rows 1 and 2, where num_legs is a possible column.\n",
      "4. String \"row:1[num_legs]\" is a well-formatted instance which gets row 1, but for just column num_legs, where num_legs is a possible column.\n",
      "5. String \"mean:num_legs[1..3]\" is a well-formatted instance which takes the mean of num_legs from rows 1 to 3, where num_legs is a possible column and mean is a valid Pandas DataFrame operation.\n",
      "6. String \"do_something:num_legs\" is a badly-formatted instance, where do_something is not a valid Pandas DataFrame operation.\n",
      "7. String \"mean:invalid_col\" is a badly-formatted instance, where invalid_col is not a possible column.\n",
      "\n",
      "Here are the possible columns:\n",
      "```\n",
      "Survived, Pclass, Name, Sex, Age, Siblings/Spouses Aboard, Parents/Children Aboard, Fare\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langchain.output_parsers import PandasDataFrameOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "import re\n",
    "\n",
    "# Titanic ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "df = pd.read_csv('data/titanic.csv')\n",
    "\n",
    "# Pandas DataFrame Output Parser ì„¤ì •\n",
    "parser = PandasDataFrameOutputParser(dataframe=df)\n",
    "\n",
    "# í˜•ì‹ ì§€ì¹¨ ì¶œë ¥\n",
    "format_instructions = parser.get_format_instructions()\n",
    "print(\"Format Instructions:\\n\", format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b43e69bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived, Pclass, Name, Sex, Age, Siblings/Spouses Aboard, Parents/Children Aboard, Fare\n"
     ]
    }
   ],
   "source": [
    "# ChatOpenAI ëª¨ë¸ ì´ˆê¸°í™”\n",
    "# model = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\" \n",
    "    You are a helpful assistant that interacts with a Pandas DataFrame.\n",
    "    The DataFrame contains the following columns: {columns}.\n",
    "    \n",
    "    Your task is to answer the user's query by generating a command in the following format:\n",
    "    {format_instructions}\n",
    "    \n",
    "    User Query: {query}    \n",
    "    \"\"\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\n",
    "        \"format_instructions\": format_instructions,\n",
    "        \"columns\": \", \".join(df.columns)\n",
    "    },\n",
    ")\n",
    "print(prompt.partial_variables['columns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "105832d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name ì»¬ëŸ¼ ì¶œë ¥\n",
      "ì˜¤ë¥˜ ë°œìƒ: Request 'The command in the required format is: \n",
      "column:Name. \n",
      "\n",
      "This will display the 'Name' column of the DataFrame. \n",
      "\n",
      "If you would like to see a specific row or a range of rows, you can modify it as follows:\n",
      "- To get a specific row: row:1[Name]\n",
      "- To get a column for specific rows: column:Name[1,3,5]\n",
      "- To get a column for a range of rows: column:Name[1..3] \n",
      "- To perform an operation: mean:Name is not valid since mean is not a string column, but  \"mean:Age\" or  \"sum:Fare\" could be used.' is not correctly formatted.                     Please refer to the format instructions.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n"
     ]
    }
   ],
   "source": [
    "# ì²´ì¸ ìƒì„±\n",
    "chain = prompt | model | parser\n",
    "\n",
    "# ëª¨ë¸ ì‘ë‹µ ë°›ê¸°\n",
    "try:\n",
    "    # **Name ì—´ì„ í‘œì‹œí•˜ì‹­ì‹œì˜¤.**\n",
    "    print('Name ì»¬ëŸ¼ ì¶œë ¥')\n",
    "    df_query = \"Show the Name column\"\n",
    "\n",
    "    parser_output = chain.invoke({\"query\": df_query})\n",
    "    print(type(parser_output))\n",
    "    print(parser_output)\n",
    "\n",
    "    # **ì²«ë²ˆì§¸ í–‰ì„ í‘œì‹œí•˜ì‹­ì‹œì˜¤.**\n",
    "    print('ì²«ë²ˆì§¸ í–‰ ì¶œë ¥')\n",
    "    df_query2 = \"Show first row\"\n",
    "\n",
    "    parser_output2 = chain.invoke({\"query\": df_query2})\n",
    "    print(parser_output2)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc1ff1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['query'] input_types={} partial_variables={'format_instructions': 'The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"data\": string  // A list of dictionaries representing table rows.\\n}\\n```'} template='\\n    You are an AI assistant that generates tabular data. \\n    You must return the data in JSON format that follows this schema:\\n\\n    {format_instructions}\\n\\n    **User Query:**\\n    {query}\\n    '\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# OpenAI ëª¨ë¸ ì´ˆê¸°í™”\n",
    "# model = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# ì‘ë‹µ ìŠ¤í‚¤ë§ˆ ì •ì˜ {data : [{},{},{}] }\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"data\", description=\"A list of dictionaries representing table rows.\"),\n",
    "]\n",
    "\n",
    "# Output Parser ì„¤ì •\n",
    "parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    You are an AI assistant that generates tabular data. \n",
    "    You must return the data in JSON format that follows this schema:\n",
    "    \n",
    "    {format_instructions}\n",
    "        \n",
    "    **User Query:**\n",
    "    {query}\n",
    "    \"\"\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9946c235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì²´ì¸ ìƒì„± (í”„ë¡¬í”„íŠ¸ â†’ ëª¨ë¸ â†’ OutputParser)\n",
    "chain = prompt | model | parser\n",
    "\n",
    "# ì‹¤í–‰ í•¨ìˆ˜\n",
    "def generate_dataframe(user_query):\n",
    "    try:\n",
    "        # ëª¨ë¸ í˜¸ì¶œ\n",
    "        json_response = chain.invoke({\"query\": user_query})\n",
    "        print(json_response)\n",
    "        \n",
    "        # ëª¨ë¸ì´ ë°˜í™˜í•œ JSONì„ Pandas DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "        df = pd.DataFrame(json_response[\"data\"])\n",
    "\n",
    "        # ê²°ê³¼ ì¶œë ¥\n",
    "        print(\"\\nğŸ”¹ Generated DataFrame:\\n\")\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89f0340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ì˜ˆì œ 1] 2024ë…„ ìƒë°˜ê¸° ì„œìš¸ ì•„íŒŒíŠ¸ í‰ê·  ë§¤ë§¤ ê°€ê²© ë°ì´í„° ìƒì„±\n",
    "print('2024ë…„ í•˜ë°˜ê¸° ì„œìš¸ ì•„íŒŒíŠ¸ í‰ê·  ë§¤ë§¤ ê°€ê²© ë°ì´í„° ìƒì„±')\n",
    "df_seoul_housing = generate_dataframe(\n",
    "    \"Create a dataset of the average apartment sale prices in Seoul for the second half of 2024 with columns: District (êµ¬), Average Price (in KRW), Number of Transactions, and Year-over-Year Change (%).\"\n",
    ")\n",
    "print(df_seoul_housing.shape)\n",
    "df_seoul_housing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
